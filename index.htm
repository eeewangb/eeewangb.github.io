<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="cye-nm">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="stylesheet" href="./jemdoc.css" type="text/css">
    <title>Bin Wang - Homepage</title>
    <style>
   
        .publications-container h2 {
            margin-bottom: 20px;
        }
    
        .pub-section-title {
            color: #000;
            font-weight: bold;
            font-size: 1.15em;
            margin: 25px 0 10px 0;
            display: block; 
        }
    
        .pub-list {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }
    
        .pub-list li {
            padding-left: 25px;  
            margin-bottom: 18px;  
            line-height: 1.6;     
        }
    
        .pub-list a {
            color: #0066cc;
            text-decoration: none;
        }
        .pub-list a:hover {
            text-decoration: underline;
        }
    </style>
    </head>

<body ryt12610="1">
    <div id="layout-content" style="margin-top:15px">
        <table>
            <tbody>
                <tr>
                    <td width="240">
                        <img src="./photo.png" width="180" alt="Profile Photo">
                    </td>
                    <td width="670">
                        <div id="toptitle">
                            <h1>Bin Wang &nbsp; </h1>
                        </div>
                        <h3>Lecturer & Post-doctoral</h3>
                        <p>
                            
                            <a href="https://dz.sdut.edu.cn/" target="_blank">School of Electrical and Electronic Engineering</a> & <a href="https://control.sdu.edu.cn/" target="_blank">School of Control Science and Engineering </a><br>
                            <a href="https://www.sdut.edu.cn/" target="_blank">Shandong University of Technology</a> & <a href="https://www.sdu.edu.cn/" target="_blank">Shandong University</a><br>
                            <br>
                            Email: <a href="mailto:dqwangbin@sdut.edu.cn">dqwangbin@sdut.edu.cn</a>
                        </p>
                        <p>
                            [<a href="https://scholar.google.com/citations?user=Uk43cI4AAAAJ&hl=zh-CN"><span style="color:purple">Google Scholar</span></a>] 
                    
                        </p>
                   
                </tr>
            </tbody>
        </table>

        <hr>

        <h2>About Me</h2>
        <p>
            I am a lecturer at the School of Electrical and Electronic Engineering, Shandong University of Technology. 
            In November 2024,  I was a Postdoctoral Researcher at the <a href="http://www.vsislab.com/"><span style="color:purple">VSISLab</span></a>, School of Control Science and Engineering, working with my postdoctoral 
            advisors Professor <a href="https://scholar.google.com/citations?user=qCWuPHsAAAAJ&hl=zh-CN"><span style="color:purple">Wei Zhang</span></a> and 
            Professor <a href="https://scholar.google.com/citations?user=-VrKJ0EAAAAJ&hl=zh-CN"><span style="color:purple">Runmin Cong</span></a>.
            Previously, I completed my doctoral degree at the School of Control Science and Engineering, Shandong University in September 2024, under the supervision of Professor Chang Falang.
            

        </p>

        <h2>Research Interests</h2>
        <ul>
            My recent research interests include:
            <li>Video Understanding (e.g., Temporal Action Recognition, Privacy Action Recognition)</li>
            <li>Embodied Artificial Intelligence (e.g., Navigation, Grasping, and Reasoning)</li>
            <li>Visual Language Models (e.g., CLIP, Prompt Tuning)</li>
        </ul>

        <h2>Openings</h2>
        <ul>
            <li><h4>Prospective Students: I am looking for motivated Master students for 2026.</h4></li>
            <li>Recruiting undergraduate research assistants year-round. Please email your CV to contact me.</li>
            <li>
            <b>请想要申请读研/本科生研究助理的同学首先读这个文档: [<a href="https://github.com/eeewangb/eeewangb.github.io/blob/main/students.md"><b>招生要求与学生培养</b></a>]</b></p>
            </li>
        </ul>

    <div class="publications-container">
    <h2>Publications</h2>

    <span class="pub-section-title">Preprints</span>
    <ul class="pub-list">
        <li>
            <b>Generalizable Deepfake Video Detection via Temporal-Frequency and Saliency-guided Network</b><br>
            Weicheng Song, Mingliang Gao, Siyou Guo, <b>Bin Wang </b> <br>
            <em>Submitted to IEEE Transactions on Dependable and Secure Computing (TDSC)</em>, 2026
        </li>
    
        <li>
            <b>GA2-CLIP: Generic Attribute Anchor for Efficient Prompt Tuning in Video-Language Models</b>[<a href="https://arxiv.org/pdf/2511.22125">pdf</a>][<a href="https://github.com/BBYL9413/GA2-CLIP">code</a>]<br>
            <b>Bin Wang </b>, Ruotong Hu, Wenqian Wang, Wentong Li, Mingliang Gao, Runmin Cong, Wei Zhang <br>
            <em>Submitted to International Conference on Machine Learning (ICML)</em>, 2026
        </li>
    
        <li>
            <b>Instruction Decomposition and Action Alignment for Vision-Language Navigation</b><br>
            Zihao Xin, Wentong Li, Yixuan Jiang, <b>Bin Wang </b>, Piji Li, Jianke Zhu, Jie Qin, Sheng-Jun Huang <br>
            <em>Submitted to International Conference on Machine Learning (ICML)</em>, 2026
        </li>
    
        <li>
            <b>TDS-CLIP: Temporal Difference Side Network for Image-to-video Transfer Learning</b>[<a href="https://arxiv.org/pdf/2408.10688">pdf</a>][<a href="https://github.com/BBYL9413/TDS-CLIP/">code</a>]<br>
            <b>Bin Wang </b>, Wentong Li, Wenqian Wang, Mingliang Gao, Runmin Cong, Wei Zhang <br>
            <em>Submitted to IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>, 2025
        </li>
    
      
        <li>
            <b>Side-Branch Enhanced Cross-Modal Framework for Zero/Few-Shot Traffic Anomaly Detection</b><br>
            Penghui Hao, Faliang Chang, Fei Wang, Chunsheng Liu, Jun Zhou, Wenqian Wang, <b>Bin Wang </b> <br>
            <em>Submitted to  Pattern Recognition (PR)</em>, 2025
        </li>
    </ul>

    <span class="pub-section-title">Selected Publications</span>
    <ul class="pub-list">
         <li>
            <b>DecoVLN: Decoupling Observation, Reasoning, and Correction for Vision-and-Language Navigation</b> <br>
            Zihao Xin, Wentong Li, Yixuan Jiang, <b>Bin Wang </b>, Runmin Cong, Jie Qin, Sheng-Jun Huang <br>
            <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2025
        </li>
        <li>
            <b>Distributed quantum model learning for traffic density estimation</b> [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885626000065">pdf</a>]<br>
            Kewen Wang, <b>Bin Wang (Corresponding author) </b>, Wenzhe Zhai, Jing-an Cheng <br>
            <em>Image and Vision Computing</em>, 2026
        </li>
        <li>
            <b>Infrared and visible image fusion via cross-modal differential and dual-axis attention network</b> [<a href="https://iopscience.iop.org/article/10.1088/1361-6501/ae0147/meta">pdf</a>] [<a href="https://github.com/lishuohui123/CDDANet">code</a>]<br>
            Shuo Li, Wei Song, Shuo Liu, <b>Bin Wang (Corresponding author)</b>, Mingliang Gao <br>
            <em>Measurement Science and Technology</em>, 2025
        </li>
        <li>
            <b>An efficient motion visual learning method for video action recognition</b> [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0957417424014635">pdf</a>]<br>
            <b>Bin Wang </b>, Faliang Chang, Chunsheng Liu, Wenqian Wang, Ruidong Ma <br>
            <em>Expert Systems with Applications</em>, 2024
        </li>
        <li>
            <b>Human–robot interaction-oriented video understanding of human actions</b> [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0952197624004056">pdf</a>]<br>
            <b>Bin Wang </b>, Faliang Chang, Chunsheng Liu, Wenqian Wang <br>
            <em>Engineering Applications of Artificial Intelligence</em>, 2024
        </li>
        <li>
            <b>TODO-Net: Temporally observed domain contrastive network for 3-D early action prediction</b> [<a href="https://ieeexplore.ieee.org/abstract/document/10530416/">pdf</a>]<br>
            Wenqian Wang, Faliang Chang, Chunsheng Liu, <b>Bin Wang </b>, Zhengzhe Liu <br>
            <em>IEEE Transactions on Neural Networks and Learning Systems</em>, 2024
        </li>
        <li>
            <b>ACF-net: appearance-guided content filter network for video captioning</b> [<a href="https://link.springer.com/article/10.1007/s11042-023-16580-7">pdf</a>]<br>
            Min Li, Dongmei Liu, Chunsheng Liu, Faliang Chang, Wenqian Wang, <b>Bin Wang </b> <br>
            <em>Multimedia Tools and Applications</em>, 2024
        </li>
        <li>
            <b>Dss-net: Dynamic self-supervised network for video anomaly detection</b> [<a href="https://ieeexplore.ieee.org/document/10174739">pdf</a>]<br>
            Peihao Wu, Wenqian Wang, Faliang Chang, Chunsheng Liu, <b>Bin Wang </b> <br>
            <em>IEEE Transactions on Multimedia</em>, 2023
        </li>
        <li>
            <b>Magi-net: Meta negative network for early activity prediction</b> [<a href="https://ieeexplore.ieee.org/document/10174739">pdf</a>]<br>
            Wenqian Wang, Faliang Chang, Jiachao Zhang, Rui Yan, Chunsheng Liu, <b>Bin Wang </b>, Mike Zheng Shou <br>
            <em>IEEE Transactions on Image Processing</em>, 2023
        </li>
        <li>
            <b>AE-Net: Adjoint enhancement network for efficient action recognition in video understanding</b> [<a href="https://ieeexplore.ieee.org/document/10174739">pdf</a>]<br>
            <b>Bin Wang </b>, Chunsheng Liu, Faliang Chang, Wenqian Wang, Nanjun Li <br>
            <em>IEEE Transactions on Multimedia</em>, 2022
        </li>
        <li>
            <b>Ga-net: a guidance aware network for skeleton-based early activity recognition</b> [<a href="https://ieeexplore.ieee.org/document/10174739">pdf</a>]<br>
            Wenqian Wang, Faliang Chang, Chunsheng Liu, Guangxin Li, <b>Bin Wang </b> <br>
            <em>IEEE Transactions on Multimedia</em>, 2021
        </li>
        </ul>
    </div>
        
        <ul>
            
        </ul>

        <h2>Academic Services</h2>
        <ul>
       
    	    <li>
            Conference Reviewer:</br> 
        	    AAAI2025, CVPR2025, ICCV2025</br>
            </li>
            <li>
            Journal Reviewer: </br>
                    IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) </br>
                    IEEE Transactions on Image Processing (TIP) </br>
                    IEEE Transactions on Multimedia (TMM) </br>
                    IEEE Transactions on Industrial Informatics (TII) </br>
                    Pattern Recognition (PR) </br>
                    Expert Systems with Applications </br>
                    Mechanical Systems and Signal Processing (MSSP) </br>
                    Artificial Intelligence in Medicine (AIIM) </br>
                </li>
            </ul>

          <h2>Teaching</h2>
        <ul>
       
    	    
            <li>Data Analysis and Mining, Shandong University of Technology, Fall Semester 2025. </li>
            
            <li>Computer Vision, Shandong University of Technology, Spring Semester 2026. </li>
            </ul>
</body>
</html>






































